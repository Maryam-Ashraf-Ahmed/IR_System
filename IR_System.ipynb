{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96d9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6467a5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'],\n",
       " ['antony', 'brutus', 'caeser', 'calpurnia'],\n",
       " ['mercy', 'worser'],\n",
       " ['brutus', 'caeser', 'mercy', 'worser'],\n",
       " ['caeser', 'mercy', 'worser'],\n",
       " ['antony', 'caeser', 'mercy'],\n",
       " ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'],\n",
       " ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'],\n",
       " ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'],\n",
       " ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('in')\n",
    "stop_words.remove('to')\n",
    "stop_words.remove('where')\n",
    "data_folder=os.path.join(os.getcwd(),'Files')\n",
    "documents=[] \n",
    "for root,folders,files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        path=os.path.join(root,file)\n",
    "        with open(path) as inf:\n",
    "            document=inf.read()\n",
    "            tokenized_documents=word_tokenize(document)\n",
    "            terms=[]\n",
    "            for word in tokenized_documents:\n",
    "                if word not in stop_words:\n",
    "                    terms.append(word)\n",
    "            documents.append(terms)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440f307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antony': [3, {0: [0], 1: [0], 5: [0]}],\n",
       " 'brutus': [3, {0: [1], 1: [1], 3: [0]}],\n",
       " 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}],\n",
       " 'cleopatra': [1, {0: [3]}],\n",
       " 'mercy': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}],\n",
       " 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}],\n",
       " 'calpurnia': [1, {1: [3]}],\n",
       " 'angels': [3, {6: [0], 7: [0], 8: [0]}],\n",
       " 'fools': [4, {6: [1], 7: [1], 8: [1], 9: [0]}],\n",
       " 'fear': [3, {6: [2], 7: [2], 9: [1]}],\n",
       " 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}],\n",
       " 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}],\n",
       " 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}],\n",
       " 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}],\n",
       " 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index=0\n",
    "positional_index={}\n",
    "for document in documents:\n",
    "    for positional , term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0]=positional_index[term][0]+1;\n",
    "            if document_index in positional_index[term][1]:\n",
    "                postional_index[term][1][document_index].append(positional)\n",
    "            else:\n",
    "                positional_index[term][1][document_index]=[positional]\n",
    "        else:\n",
    "            positional_index[term]=[]\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_index]=[positional]\n",
    "    document_index+=1  \n",
    "positional_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9f6db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Queryantony brutus\n",
      "[[0, 1], [0, 1], [], [0], [], [0], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "query=input('Input Query')\n",
    "final_list=[[] for i in range(10)]\n",
    "for word in query.split():\n",
    "    for key in positional_index[word][1].keys():\n",
    "        if final_list[key]!=[]:\n",
    "            if final_list[key][-1] == positional_index[word][1][key][0]-1:\n",
    "                final_list[key].append(positional_index[word][1][key][0])\n",
    "        else:\n",
    "            final_list[key].append(positional_index[word][1][key][0])\n",
    "\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50399e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for position , List in enumerate(final_list,start=1):\n",
    "    if len(List) == len(query.split()):\n",
    "        print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3405a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0  1  2  3  4  5  6  7  8  9\n",
      "antony     1  1  0  0  0  1  0  0  0  0\n",
      "brutus     1  1  0  1  0  0  0  0  0  0\n",
      "caeser     1  1  0  1  1  1  0  0  0  0\n",
      "cleopatra  1  0  0  0  0  0  0  0  0  0\n",
      "mercy      1  0  1  1  1  1  0  0  0  0\n",
      "worser     1  0  1  1  1  0  0  0  0  0\n",
      "calpurnia  0  1  0  0  0  0  0  0  0  0\n",
      "angels     0  0  0  0  0  0  1  1  1  0\n",
      "fools      0  0  0  0  0  0  1  1  1  1\n",
      "fear       0  0  0  0  0  0  1  1  0  1\n",
      "in         0  0  0  0  0  0  1  1  1  1\n",
      "rush       0  0  0  0  0  0  1  1  1  1\n",
      "to         0  0  0  0  0  0  1  1  1  1\n",
      "tread      0  0  0  0  0  0  1  1  1  1\n",
      "where      0  0  0  0  0  0  1  1  1  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "All_words=[]\n",
    "for doc in documents:\n",
    "    for word in doc:\n",
    "        All_words.append(word)\n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(All_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word]+=1\n",
    "    return words_found\n",
    "term_freq=pd.DataFrame(get_term_freq(documents[0]).values(),index=get_term_freq(documents[0]).keys())\n",
    "for i in range(1,len(documents)):\n",
    "    term_freq[i]=get_term_freq(documents[i]).values()\n",
    "print(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a76e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3    4    5    6    7    8    9\n",
      "antony     1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
      "brutus     1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "caeser     1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
      "cleopatra  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "mercy      1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
      "worser     1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "calpurnia  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "angels     0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0\n",
      "fools      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "fear       0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0\n",
      "in         0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "rush       0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "to         0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "tread      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "where      0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_weighted_term_freq(x):\n",
    "    if x > 0:\n",
    "        return math.log10(x) + 1\n",
    "    return 0\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    term_freq[i] = term_freq[i].apply(get_weighted_term_freq)\n",
    "print(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb3199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          freq       idf\n",
      "antony     3.0  0.522879\n",
      "brutus     3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "mercy      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angels     3.0  0.522879\n",
      "fools      4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n"
     ]
    }
   ],
   "source": [
    "tfd=pd.DataFrame(columns=['freq','idf'])\n",
    "for i in range(len(term_freq)):\n",
    "    frequency =term_freq.iloc[i].values.sum()\n",
    "    tfd.loc[i,'freq']=frequency\n",
    "    tfd.loc[i,'idf']=math.log10(10/(float(frequency)))\n",
    "tfd.index=term_freq.index\n",
    "print(tfd)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988fb59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         1        2         3        4         5         6  \\\n",
      "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "                  7         8         9  \n",
      "antony          0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angels     0.522879  0.522879       0.0  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n"
     ]
    }
   ],
   "source": [
    "term_freq_inve_doc_freq=term_freq.multiply(tfd['idf'],axis=0)\n",
    "print(term_freq_inve_doc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9637a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Length\n",
      "          0         1         2         3         4        5         6  \\\n",
      "0  1.373462  1.279618  0.498974  0.782941  0.582747  0.67427  1.223496   \n",
      "\n",
      "          7         8         9  \n",
      "0  1.223496  1.106137  1.106137  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "document_length = pd.DataFrame()\n",
    "\n",
    "def get_docs_length(col):\n",
    "    return np.sqrt(term_freq_inve_doc_freq[col].apply(lambda x: x**2).sum())\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    document_length.loc[0, column] = get_docs_length(column)\n",
    "print('Document Length')\n",
    "print(document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc46db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomalized TF.IDF\n",
      "                  0         1         2         3         4         5  \\\n",
      "antony     0.380701  0.408621  0.000000  0.000000  0.000000  0.775474   \n",
      "brutus     0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
      "caeser     0.219176  0.235250  0.000000  0.384486  0.516570  0.446453   \n",
      "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "mercy      0.219176  0.000000  0.603298  0.384486  0.516570  0.446453   \n",
      "worser     0.289735  0.000000  0.797516  0.508263  0.682869  0.000000   \n",
      "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
      "angels     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fools      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "                  6         7         8         9  \n",
      "antony     0.000000  0.000000  0.000000  0.000000  \n",
      "brutus     0.000000  0.000000  0.000000  0.000000  \n",
      "caeser     0.000000  0.000000  0.000000  0.000000  \n",
      "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
      "mercy      0.000000  0.000000  0.000000  0.000000  \n",
      "worser     0.000000  0.000000  0.000000  0.000000  \n",
      "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
      "angels     0.427365  0.427365  0.472707  0.000000  \n",
      "fools      0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365  0.000000  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "normalized_term_freq_idf = pd.DataFrame()\n",
    "\n",
    "def get_normalized(col, x):\n",
    "    try:\n",
    "        return x / document_length[col].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "for column in term_freq_inve_doc_freq.columns:\n",
    "    normalized_term_freq_idf[column] = term_freq_inve_doc_freq[column].apply(lambda x : get_normalized(column, x))\n",
    "\n",
    "print('Nomalized TF.IDF')\n",
    "print(normalized_term_freq_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f433ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tf  w_tf       idf    tf_idf  normalized\n",
      "antony      1   1.0  0.522879  0.522879           0\n",
      "brutus      1   1.0  0.522879  0.522879           0\n",
      "caeser      0   0.0       0.0       0.0           0\n",
      "cleopatra   0   0.0       0.0       0.0           0\n",
      "mercy       0   0.0       0.0       0.0           0\n",
      "worser      0   0.0       0.0       0.0           0\n",
      "calpurnia   0   0.0       0.0       0.0           0\n",
      "angels      0   0.0       0.0       0.0           0\n",
      "fools       0   0.0       0.0       0.0           0\n",
      "fear        0   0.0       0.0       0.0           0\n",
      "in          0   0.0       0.0       0.0           0\n",
      "rush        0   0.0       0.0       0.0           0\n",
      "to          0   0.0       0.0       0.0           0\n",
      "tread       0   0.0       0.0       0.0           0\n",
      "where       0   0.0       0.0       0.0           0\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(doc):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.remove('in')\n",
    "    stop_words.remove('to')\n",
    "    stop_words.remove('where')\n",
    "    prepared_doc = []\n",
    "    for term in token_docs:\n",
    "        if term not in stop_words:\n",
    "            prepared_doc.append(term)\n",
    "    return prepared_doc\n",
    "\n",
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x) + 1\n",
    "    except:\n",
    "        return 0 \n",
    "q ='antony brutus'\n",
    "\n",
    "query = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "query['tf'] = [1 if x in preprocessing(q) else 0 for x in list(normalized_term_freq_idf.index)]\n",
    "query['w_tf'] = query['tf'].apply(lambda x : get_w_tf(x))\n",
    "product = normalized_term_freq_idf.multiply(query['w_tf'], axis=0)\n",
    "query['idf'] = tfd['idf'] * query['w_tf']\n",
    "query['tf_idf'] = query['w_tf'] * query['idf']\n",
    "query['normalized'] = 0\n",
    "print(query)\n",
    "##################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015f1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product (query*matched doc)\n",
      "               0         1\n",
      "antony  0.269196  0.288939\n",
      "brutus  0.269196  0.288939\n",
      "\n",
      "product sum\n",
      "0    0.538393\n",
      "1    0.577877\n",
      "dtype: float64\n",
      "\n",
      "Query Length\n",
      "0.7394622130520805\n",
      "\n",
      "Cosine Simliarity\n",
      "0    0.538393\n",
      "1    0.577877\n",
      "dtype: float64\n",
      "\n",
      "Returned docs\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryam\\AppData\\Local\\Temp\\ipykernel_17156\\2141543470.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n"
     ]
    }
   ],
   "source": [
    " for i in range(len(query)):\n",
    "        query['normalized'].iloc[i] = float(query['idf'].iloc[i]) / math.sqrt(sum(query['idf'].values**2))\n",
    "query\n",
    "##################################################################################\n",
    "product2 = product.multiply(query['normalized'], axis=0)\n",
    "product2 \n",
    "##################################################################################\n",
    "scores = {}\n",
    "for col in product2.columns:\n",
    "    if 0 in product2[col].loc[preprocessing(q)].values:\n",
    "         pass\n",
    "    else:\n",
    "         scores[col] = product2[col].sum()\n",
    "scores\n",
    "#################################################################################\n",
    "product_result = product2[list(scores.keys())].loc[preprocessing(q)]\n",
    "print()\n",
    "print('Product (query*matched doc)')\n",
    "print(product_result)\n",
    "print()\n",
    "print('product sum')\n",
    "print(product_result.sum())\n",
    "print()\n",
    "print('Query Length')\n",
    "q_len = math.sqrt(sum([x**2 for x in query['idf'].loc[preprocessing(q)]]))\n",
    "print(q_len)\n",
    "print()\n",
    "print('Cosine Simliarity')\n",
    "print(product_result.sum())\n",
    "print()\n",
    "sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Returned docs')\n",
    "for typle in sorted_scores:\n",
    "    print(typle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b67561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
